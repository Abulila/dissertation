This chapter motivates and defines \emph{Persistent Memory Consistency}.
This should be considered future work and I welcome feedback.
I first define the problem and then give examples of persistent memory consistency models.
In the next chapter I give examples of programming patterns, why they require relaxed persistent consistency models, and possible optimizations.

\section{Introduction}
\label{sec:PMC:Intro}

Future NVRAMs will provide a persistent store with the programming interface of modern main memories.
While such technologies could revolutionize the design of recoverable systems and durable storage, questions remain regarding device performance and the NVRAM programming model.
Chapters~\fixme{ref} and~\fixme{ref} consider an abstract \emph{persist barrier} capable of enforcing persist order or blocking until previous persists complete.
Instead of considering an implementation or exact semantics of these barriers, I instead looked at the effect average persist barrier latency had on OLTP software design.
This project delves into the details of persist barriers, considering their implementation, performance impact, and programming model.

Persist barriers exist as a tool for programmers to ensure correct persistence behavior, while at the same time improving performance.
Imagine an NVRAM model where persist barriers do not exist.
Without persist barriers, the only way for the programmer to reason about persist order is for all persists to truly occur in program order.
This is in fact a popular model for DRAM programming, but the volatile semantics of DRAM writes to execute to fast caches.
NVRAM persists, on the other hand, must always execute to a long latency memory; executing all NVRAM persists in-order will introduce frequent, substantial stalls.
Persist barriers remove these stalls by allowing all persists between barriers to occur in parallel.
This is a prime example of using a more sophisticated programming model to provide performance optimizations.

Additional questions remain when persistent memory is shared between threads or processes.
Currently, memory consistency models define how threads communicate and what barriers are necessary to ensure proper behavior.
Memory consistency models exist because processors prefer to run instructions out of order -- a pervasive optimization that significantly complicates multi-threaded programming.
While consistency models control the order in which threads observe reads and writes, there is no similar definition for the order in which persists occur, or how persist order is enforced across communicating threads.
Furthermore, persistent memories often care about the actual timing of persists, not just relative ordering -- for example, system calls must make sure that all previous persists have completed before notifying the user.
In this case there is no alternative but to block until all data persists.
These mechanisms are not present in existing consistency models.

While memory consistency models provide a starting point for considering persistent consistency models, the performance differences of volatile memory systems/DRAM and NVRAM will require new programming models for NVRAM.
In fact, the consistency and persistence models may be de-coupled.
That is, the rules that define load and store order might be different between how \emph{values} are communicated and how \emph{persist order} is enforced.

I wish to extend memory consistency models with persistence semantics to address these concerns.
The goals are to determine how multi-threaded consistency interacts with persistence, how to relax consistency/persistency models to provide high performance and an easily programmable interface, and identify programming patterns likely to cause NVRAM bottlenecks alongside potential optimizations.
All of these will eventually lead to the design of new persistent memory consistency models and implementations, yet that is most likely outside the scope of this project.

The remainder of this chapter provides a brief background of memory consistency models before considering simple examples of persistent memory consistency models.
In addition, I examine previous work, highlighting strengths and weaknesses, and placing it into my persistent memory consistency taxonomy.

\section{Memory consistency models}
\label{sec:PMC:MemoryConsistency}

This section provides a background on memory consistency models, focusing on two simple models: Sequential Consistency (SC) and Total Store Order (TSO).
For the remainder of this section I am referring solely to volatile writes without considering for NVRAM persists.
This discussion assumes that caches are completely coherent -- that is, any two accesses to a cache line (by any core/thread), where at least one access is a store, have a total order.
While incredibly relaxed memory models may allow stale cached values to be read, I do not consider that here.

Consistency models define the order that threads observe loads and stores.
While every thread observes its own execution in program order, it may appear that remote threads execute out of order.
Processors (and compilers) are free to reorder instructions to accelerate performance so long as they produce equivalent results.
When examining a program ordering restrictions can be observed through register and memory dependencies.
However, it is much more difficult to observe memory dependencies between threads.
Loads and stores that are independent from a single-threaded point of view may in fact interact with other threads.
Reordering these memory accesses can result in unintended program behavior.

Two popular solutions to this problem are to 1) force all threads to observe the loads and stores of other threads in a globally defined order (SC) or 2) relax this guarantee, introducing memory barriers that allow the programmer to enforce a certain order when necessary (e.g., TSO).
While relaxing consistency may provide higher performance, it places a greater burden on the programmer to correctly use memory barriers.

\textbf{Sequential Consistency.}
Sequential consistency provides the most intuitive programming model, yet necessarily the worst performance (although modern techniques involving speculation provide high performance).
All loads and stores across threads appear in some globally consistent order that is an interleaving of the program order of all threads.
There is no need for the programmer to consider that memory instructions might reorder or use memory barriers.

\textbf{Total Store Order.}
TSO provides greater performance than SC at the cost of requiring the programmer to insert memory barriers.
Most memory operations are still observed to occur in program order: 1) stores may not reorder with other stores, 2) loads may not reorder with other loads, and 3) a store that occurs after a load may not reorder and appear to occur before that load.
However, loads that occur after a store in program order may reorder and bypass the store, appearing to occur before the store.
The justification for doing this is that stores are typically not on the application's critical path -- they simply write into the cache and do not insert delays.
Loads, on the other hand, may cause delays if they miss in the cache and must execute to a higher level cache or main memory.
These loads must start as soon as possible to minimize delays.

The programmer is responsible for locating any code where allowing a load to bypass a store causes an incorrect result.
In this case, a barrier is provided by the architecture to force all loads to delay until the store appears to other threads (or rerun those loads if some other thread stores to those addresses).

The next section extends these simple memory consistency models to investigate how persistence interacts with communicating threads.

\section{Persistent Memory Consistency Models}
\label{sec:PMC:PersistenceModels}

While memory consistency models control the order that loads and stores are observed across threads, they give no guarantees on persistence.
I outline several persistent consistency models, starting with constrained models, and then considering more relaxed models.

\subsection{Persistent Sequential Consistency}
\label{sec:PMC:PersistenceModels:PSC}

The first model couples persistence to the sequential consistency model as Persistent Sequential Consistency (PSC).
All loads and stores (including persists) appear to occur in a globally defined order as an interleaving of valid program orders.
Whereas volatile memory systems control this solely by controlling the order in which memory actions become visible from each processor, NVRAM used for recovery must treat every point in time as a possible failure, observing the persistent state.
Achieving a globally consistent persist order requires that persists \emph{actually} occur in-order from each thread, or that sequential batches of persists occur atomically, so that no failure may observe an intermediate state (NVRAM's atomically persistable size is likely to be small -- 8 bytes usually assumed).
Additionally, all data sharing propagates ordering dependencies between persists.

Consider Figure~\fixme{ref}.
The letters correspond to persistent variables, and all are initialized to 0.
Assuming threads execute under a sequential consistency model (i.e., they observe shared values from that model) and persist orders are enforced according to the PSC model, at no point may we observe that A=1, C=1, and B=0.
Doing so would violate the model by allowing thread 1 to observe a persist from thread 2 (B=1) and then persist an additional value before B persists.
Even if the program executes according to SC, persistence order must also be observed.

The problem with PSC is that all persists are ordered.
If persist latency is large (expected to be at least hundreds of nanoseconds up to several microseconds) every persist will incur this penalty; there is no opportunity to execute persists from the same thread in parallel.
While persists across threads may occur in parallel, sharing introduces additional dependencies, increasing delays further.
The next model relaxes the multi-threaded constraint.

\subsection{Total Persist Order}
\label{sec:PMC:PersistenceModels:TPO}
